{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Übung 6: Transfer learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neuronal Netze benötigen oft eine große Menge an Trainingsdaten, damit es nicht zu overfitting kommt. Transfer learning erlaubt es, mit relativ geringen Datenmenge dennoch erfolgreiche große Netze zu trainieren. Dabei verwendet man ein bereits auf einen anderen Datensatz (z.b. ImageNet) vortrainiertes Netzwerk, und ersetzt nur das letzte Layer durch ein neues. In dieser Übung geht es darum, ein Netzwerk für die Erkennung von Geparden und Leoparden in der freien Wildbahn zu trainineren. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daten laden\n",
    "\n",
    "Lade die Daten hier herunter: http://tonic.imp.fu-berlin.de/cv_data/data.tar.gz\n",
    "\n",
    "Die Daten wurde bereits in ein Trainings- und Validierungsset geteilt. Die Ordnerstruktur ist wie bei vielen Bildklassifierungsdatensetzen so aufgebaut. Es gibt zwei Unterordner für die Trainings- und Validierunsdaten. In diesen Ordnern liegen dann jeweils alle Bilder von einer Klasse in einem Unterordner mit dem Namen der Klasse.\n",
    "\n",
    "Ein Beispiel: Die Trainingsbilder für die Klasse \"cheetah\" liegen in dem Unterordner train/cheetah\n",
    "\n",
    "Diese Orderstruktur wird auch von dem in keras enhaltenen ImageDataGenerator unterstützt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session, get_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "set_session(tf.Session(config=config))\n",
    "\n",
    "import os\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "image_input_size = (32, 32)\n",
    "data_path = 'data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17857 images belonging to 3 classes.\n",
      "Found 1915 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_data_path = os.path.join(data_path, 'train')\n",
    "val_data_path = os.path.join(data_path, 'val')\n",
    "\n",
    "izw_classes = ('unknown', 'cheetah', 'leopard')\n",
    "\n",
    "generator = ImageDataGenerator(horizontal_flip=True)\n",
    "val_generator = ImageDataGenerator(horizontal_flip=False)\n",
    "\n",
    "train_gen = generator.flow_from_directory(\n",
    "    train_data_path, \n",
    "    target_size=image_input_size,\n",
    "    classes=izw_classes,\n",
    "    batch_size=batch_size)\n",
    "\n",
    "val_gen = val_generator.flow_from_directory(\n",
    "    val_data_path, \n",
    "    target_size=image_input_size,\n",
    "    classes=izw_classes,\n",
    "    batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training ohne transfer learning\n",
    "\n",
    "Trainiere zuerst ein kleines Classifer-Netzwerk ohne transfer learning. Falls du keine Grafikkarte hast, solltest du nicht die volle Auflösung (siehe Variable image_input_size) verwenden, da das Training sonst zu lange dauert. Eine Bildgröße von 32x32 Pixeln wäre zum Beispiel möglich."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 30, 30, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 30, 15, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 28, 13, 32)        4640      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 28, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 28, 6, 16)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 26, 4, 64)         9280      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 26, 4, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 26, 2, 32)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1664)              0         \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 1664)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1664)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 4995      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 19,811\n",
      "Trainable params: 19,811\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.utils.np_utils import to_categorical\n",
    "    \n",
    "\n",
    "#convert the traing set to categorical \n",
    "#number_of_classes = 3\n",
    "#to_categorical_tensor(train_gen, number_of_classes)\n",
    "#to_categorical_tensor(val_gen, number_of_classes)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(32, 32, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), data_format=\"channels_first\"))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), data_format=\"channels_first\"))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), data_format=\"channels_first\"))\n",
    "\n",
    "model.add(Flatten())\n",
    "#model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(3))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# Compile model\n",
    "epochs = 50\n",
    "learning_rate = 0.1\n",
    "decay_rate = learning_rate / epochs\n",
    "momentum = 0.8\n",
    "sgd = SGD(lr=learning_rate, momentum=momentum, decay=decay_rate, nesterov=False)\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Variable *= will be deprecated. Use variable.assign_mul if you want assignment to the variable value or 'x = x * y' if you want a new python Tensor object.\n",
      "Epoch 1/50\n",
      "56/56 [==============================] - 32s 573ms/step - loss: 6.1026 - acc: 0.6205 - val_loss: 4.7491 - val_acc: 0.7054\n",
      "Epoch 2/50\n",
      "56/56 [==============================] - 28s 508ms/step - loss: 5.8644 - acc: 0.6362 - val_loss: 4.7491 - val_acc: 0.7054\n",
      "Epoch 3/50\n",
      "56/56 [==============================] - 31s 552ms/step - loss: 5.9094 - acc: 0.6334 - val_loss: 4.7491 - val_acc: 0.7054\n",
      "Epoch 4/50\n",
      "56/56 [==============================] - 32s 566ms/step - loss: 5.5946 - acc: 0.6529 - val_loss: 4.7491 - val_acc: 0.7054\n",
      "Epoch 5/50\n",
      "56/56 [==============================] - 30s 539ms/step - loss: 5.6575 - acc: 0.6490 - val_loss: 4.7491 - val_acc: 0.7054\n",
      "Epoch 6/50\n",
      "56/56 [==============================] - 28s 508ms/step - loss: 5.3427 - acc: 0.6685 - val_loss: 4.7491 - val_acc: 0.7054\n",
      "Epoch 7/50\n",
      "56/56 [==============================] - 28s 495ms/step - loss: 5.4596 - acc: 0.6613 - val_loss: 4.7491 - val_acc: 0.7054\n",
      "Epoch 8/50\n",
      "56/56 [==============================] - 29s 509ms/step - loss: 5.6305 - acc: 0.6507 - val_loss: 4.7491 - val_acc: 0.7054\n",
      "Epoch 9/50\n",
      "56/56 [==============================] - 30s 529ms/step - loss: 5.7565 - acc: 0.6429 - val_loss: 4.7491 - val_acc: 0.7054\n",
      "Epoch 10/50\n",
      "56/56 [==============================] - 29s 525ms/step - loss: 5.8702 - acc: 0.6358 - val_loss: 4.7491 - val_acc: 0.7054\n",
      "Epoch 11/50\n",
      "56/56 [==============================] - 27s 491ms/step - loss: 5.5676 - acc: 0.6546 - val_loss: 4.7491 - val_acc: 0.7054\n",
      "Epoch 12/50\n",
      "56/56 [==============================] - 29s 520ms/step - loss: 5.5676 - acc: 0.6546 - val_loss: 4.7491 - val_acc: 0.7054\n",
      "Epoch 13/50\n",
      "56/56 [==============================] - 30s 529ms/step - loss: 5.6755 - acc: 0.6479 - val_loss: 4.7491 - val_acc: 0.7054\n",
      "Epoch 14/50\n",
      "56/56 [==============================] - 28s 493ms/step - loss: 5.5316 - acc: 0.6568 - val_loss: 4.7491 - val_acc: 0.7054\n",
      "Epoch 15/50\n",
      "56/56 [==============================] - 27s 486ms/step - loss: 5.5513 - acc: 0.6556 - val_loss: 4.7491 - val_acc: 0.7054\n",
      "Epoch 16/50\n",
      "56/56 [==============================] - 27s 483ms/step - loss: 5.6395 - acc: 0.6501 - val_loss: 4.7491 - val_acc: 0.7054\n",
      "Epoch 17/50\n",
      "56/56 [==============================] - 27s 476ms/step - loss: 5.9993 - acc: 0.6278 - val_loss: 4.7491 - val_acc: 0.7054\n",
      "Epoch 18/50\n",
      "56/56 [==============================] - 27s 490ms/step - loss: 5.8374 - acc: 0.6378 - val_loss: 4.7491 - val_acc: 0.7054\n",
      "Epoch 19/50\n",
      "56/56 [==============================] - 26s 473ms/step - loss: 5.7655 - acc: 0.6423 - val_loss: 4.7491 - val_acc: 0.7054\n",
      "Epoch 20/50\n",
      "56/56 [==============================] - 29s 520ms/step - loss: 5.7385 - acc: 0.6440 - val_loss: 4.7491 - val_acc: 0.7054\n",
      "Epoch 21/50\n",
      "56/56 [==============================] - 26s 463ms/step - loss: 5.7655 - acc: 0.6423 - val_loss: 4.7491 - val_acc: 0.7054\n",
      "Epoch 22/50\n",
      "56/56 [==============================] - 25s 446ms/step - loss: 5.9633 - acc: 0.6300 - val_loss: 4.7491 - val_acc: 0.7054\n",
      "Epoch 23/50\n",
      "56/56 [==============================] - 25s 443ms/step - loss: 5.4507 - acc: 0.6618 - val_loss: 4.7491 - val_acc: 0.7054\n",
      "Epoch 24/50\n",
      "56/56 [==============================] - 26s 467ms/step - loss: 5.6215 - acc: 0.6512 - val_loss: 4.7491 - val_acc: 0.7054\n",
      "Epoch 25/50\n",
      "56/56 [==============================] - 25s 454ms/step - loss: 5.8014 - acc: 0.6401 - val_loss: 4.7491 - val_acc: 0.7054\n",
      "Epoch 26/50\n",
      "56/56 [==============================] - 26s 456ms/step - loss: 5.4686 - acc: 0.6607 - val_loss: 4.7491 - val_acc: 0.7054\n",
      "Epoch 27/50\n",
      "56/56 [==============================] - 28s 498ms/step - loss: 5.6845 - acc: 0.6473 - val_loss: 4.7491 - val_acc: 0.7054\n",
      "Epoch 28/50\n",
      "56/56 [==============================] - 28s 494ms/step - loss: 5.8702 - acc: 0.6358 - val_loss: 4.7491 - val_acc: 0.7054\n",
      "Epoch 29/50\n",
      "56/56 [==============================] - 28s 500ms/step - loss: 5.5766 - acc: 0.6540 - val_loss: 4.7491 - val_acc: 0.7054\n",
      "Epoch 30/50\n",
      "56/56 [==============================] - 27s 473ms/step - loss: 5.8464 - acc: 0.6373 - val_loss: 4.7491 - val_acc: 0.7054\n",
      "Epoch 31/50\n",
      "56/56 [==============================] - 25s 449ms/step - loss: 5.7025 - acc: 0.6462 - val_loss: 4.7491 - val_acc: 0.7054\n",
      "Epoch 32/50\n",
      "56/56 [==============================] - 26s 471ms/step - loss: 5.5136 - acc: 0.6579 - val_loss: 4.7491 - val_acc: 0.7054\n",
      "Epoch 33/50\n",
      "56/56 [==============================] - 27s 477ms/step - loss: 5.6126 - acc: 0.6518 - val_loss: 4.7491 - val_acc: 0.7054\n",
      "Epoch 34/50\n",
      "56/56 [==============================] - 32s 564ms/step - loss: 5.9723 - acc: 0.6295 - val_loss: 4.7491 - val_acc: 0.7054\n",
      "Epoch 35/50\n",
      "56/56 [==============================] - 28s 492ms/step - loss: 5.6575 - acc: 0.6490 - val_loss: 4.7491 - val_acc: 0.7054\n",
      "Epoch 36/50\n",
      "56/56 [==============================] - 26s 472ms/step - loss: 5.6755 - acc: 0.6479 - val_loss: 4.7491 - val_acc: 0.7054\n",
      "Epoch 37/50\n",
      "56/56 [==============================] - 26s 471ms/step - loss: 5.6575 - acc: 0.6490 - val_loss: 4.7491 - val_acc: 0.7054\n",
      "Epoch 38/50\n",
      "56/56 [==============================] - 30s 536ms/step - loss: 5.6036 - acc: 0.6523 - val_loss: 4.7491 - val_acc: 0.7054\n",
      "Epoch 39/50\n",
      "56/56 [==============================] - 28s 498ms/step - loss: 5.4883 - acc: 0.6595 - val_loss: 4.7491 - val_acc: 0.7054\n",
      "Epoch 40/50\n",
      "56/56 [==============================] - 27s 476ms/step - loss: 5.8914 - acc: 0.6345 - val_loss: 4.7491 - val_acc: 0.7054\n",
      "Epoch 41/50\n",
      "56/56 [==============================] - 27s 473ms/step - loss: 5.6395 - acc: 0.6501 - val_loss: 4.7491 - val_acc: 0.7054\n",
      "Epoch 42/50\n",
      "56/56 [==============================] - 26s 472ms/step - loss: 5.6036 - acc: 0.6523 - val_loss: 4.7491 - val_acc: 0.7054\n",
      "Epoch 43/50\n",
      "56/56 [==============================] - 27s 480ms/step - loss: 5.5856 - acc: 0.6535 - val_loss: 4.7491 - val_acc: 0.7054\n",
      "Epoch 44/50\n",
      "56/56 [==============================] - 30s 541ms/step - loss: 5.4776 - acc: 0.6602 - val_loss: 4.7491 - val_acc: 0.7054\n",
      "Epoch 45/50\n",
      "56/56 [==============================] - 32s 568ms/step - loss: 5.9332 - acc: 0.6319 - val_loss: 4.7491 - val_acc: 0.7054\n",
      "Epoch 46/50\n",
      "56/56 [==============================] - 30s 528ms/step - loss: 5.7385 - acc: 0.6440 - val_loss: 4.7491 - val_acc: 0.7054\n",
      "Epoch 47/50\n",
      "56/56 [==============================] - 30s 537ms/step - loss: 5.9723 - acc: 0.6295 - val_loss: 4.7491 - val_acc: 0.7054\n",
      "Epoch 48/50\n",
      "56/56 [==============================] - 30s 527ms/step - loss: 5.8194 - acc: 0.6390 - val_loss: 4.7491 - val_acc: 0.7054\n",
      "Epoch 49/50\n",
      "56/56 [==============================] - 28s 502ms/step - loss: 5.6935 - acc: 0.6468 - val_loss: 4.7491 - val_acc: 0.7054\n",
      "Epoch 50/50\n",
      "56/56 [==============================] - 28s 497ms/step - loss: 5.5316 - acc: 0.6568 - val_loss: 4.7491 - val_acc: 0.7054\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "`save_weights` requires h5py.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-88e5fdb1cd4a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'wights_1.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36msave_weights\u001b[0;34m(self, filepath, overwrite)\u001b[0m\n\u001b[1;32m    740\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mh5py\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 742\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'`save_weights` requires h5py.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    743\u001b[0m         \u001b[0;31m# If file exists and should not be overwritten:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    744\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0moverwrite\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: `save_weights` requires h5py."
     ]
    }
   ],
   "source": [
    "# Fit the model \n",
    "model.fit_generator(\n",
    "        train_gen,\n",
    "        steps_per_epoch=1800 // batch_size,\n",
    "        epochs=50,\n",
    "        validation_data=val_gen,\n",
    "        validation_steps=250 // batch_size)\n",
    "\n",
    "\n",
    "model.save_weights('wights_1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Erstelle eine Confusion matrix basierend auf den Ausgaben des Netzes für die Validierungsdaten und berechne den ROC AUC für die Klasse cheetah. Du kannst hierfür optional die scikit-learn Bibliothek verwenden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretrained network\n",
    "\n",
    "Lade nun ein auf Imagenet vortrainiertes Netzwerk und klassifiziere damit die Validierungsdaten. Eine Anleitung für keras findest du hier: https://keras.io/applications\n",
    "\n",
    "Du kannst selber entscheiden, welche Netzwerkarchitektur du verwendest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Da der ImageNet-Datensatz auch die Klassen cheetah und leopard enthält, können wir sogar ohne transfer learning das vortrainierte Netzwerk evaluieren. Interpretiere alle Klassen außer cheetah und leopard als unknown und berechne wie im vorherigen Schritt die Confusion matrix und den ROC AUC score für die Klasse cheetah."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer learning\n",
    "\n",
    "Das vortrainierte Netzwerk kann nun mit unseren Daten weitertrainiert werden. Ersetze dafür das letzte Layer in dem Netzwerk mit einem Dense Layer mit 3 Ausgaben für unsere Klassen cheetah, leopard und unknown. Du kannst selbst entscheiden, ob du nun das komplette Netzwerk mit trainierst oder nur das neu eingefügte, letzte Layer.\n",
    "\n",
    "Auch hierfür kannst du dich wieder an der keras Anleitung orientieren: https://keras.io/applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluiere das so trainierte Netzwerk wie in den letzten beiden Aufgaben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auswertung\n",
    "\n",
    "Beschreibe kurz qualitativ die Resultate. Wie unterscheiden sich die trainierten Netzwerke, zum Beispiel im Bezug auf die Genauigkeit oder die Laufzeit? Welche Entscheidungen musstest du bei der Erfüllung der Aufgaben treffen und warum hast du dich für den von dir gewählten Weg entschieden?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
