{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Übung 6: Transfer learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neuronal Netze benötigen oft eine große Menge an Trainingsdaten, damit es nicht zu overfitting kommt. Transfer learning erlaubt es, mit relativ geringen Datenmenge dennoch erfolgreiche große Netze zu trainieren. Dabei verwendet man ein bereits auf einen anderen Datensatz (z.b. ImageNet) vortrainiertes Netzwerk, und ersetzt nur das letzte Layer durch ein neues. In dieser Übung geht es darum, ein Netzwerk für die Erkennung von Geparden und Leoparden in der freien Wildbahn zu trainineren. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daten laden\n",
    "\n",
    "Lade die Daten hier herunter: http://tonic.imp.fu-berlin.de/cv_data/data.tar.gz\n",
    "\n",
    "Die Daten wurde bereits in ein Trainings- und Validierungsset geteilt. Die Ordnerstruktur ist wie bei vielen Bildklassifierungsdatensetzen so aufgebaut. Es gibt zwei Unterordner für die Trainings- und Validierunsdaten. In diesen Ordnern liegen dann jeweils alle Bilder von einer Klasse in einem Unterordner mit dem Namen der Klasse.\n",
    "\n",
    "Ein Beispiel: Die Trainingsbilder für die Klasse \"cheetah\" liegen in dem Unterordner train/cheetah\n",
    "\n",
    "Diese Orderstruktur wird auch von dem in keras enhaltenen ImageDataGenerator unterstützt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yamenjeries/.pyenv/versions/3.6.4/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session, get_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "set_session(tf.Session(config=config))\n",
    "\n",
    "import os\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import warnings; warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "image_input_size = (32, 32)\n",
    "data_path = 'data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17857 images belonging to 3 classes.\n",
      "Found 1915 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_data_path = os.path.join(data_path, 'train')\n",
    "val_data_path = os.path.join(data_path, 'val')\n",
    "\n",
    "izw_classes = ('unknown', 'cheetah', 'leopard')\n",
    "\n",
    "generator = ImageDataGenerator(horizontal_flip=True)\n",
    "val_generator = ImageDataGenerator(horizontal_flip=False)\n",
    "\n",
    "train_gen = generator.flow_from_directory(\n",
    "    train_data_path, \n",
    "    target_size=image_input_size,\n",
    "    classes=izw_classes,\n",
    "    batch_size=batch_size)\n",
    "\n",
    "val_gen = val_generator.flow_from_directory(\n",
    "    val_data_path, \n",
    "    target_size=image_input_size,\n",
    "    classes=izw_classes,\n",
    "    batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training ohne transfer learning\n",
    "\n",
    "Trainiere zuerst ein kleines Classifer-Netzwerk ohne transfer learning. Falls du keine Grafikkarte hast, solltest du nicht die volle Auflösung (siehe Variable image_input_size) verwenden, da das Training sonst zu lange dauert. Eine Bildgröße von 32x32 Pixeln wäre zum Beispiel möglich."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 30, 30, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 30, 15, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 29, 14, 64)        4160      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 29, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 29, 7, 32)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 6496)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 19491     \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 3)                 12        \n",
      "=================================================================\n",
      "Total params: 24,559\n",
      "Trainable params: 24,559\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras import optimizers\n",
    "\n",
    "\n",
    "\n",
    "input_shape = (32, 32, 3)\n",
    "lr = 0.0004\n",
    "epochs = 20\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), data_format=\"channels_first\"))\n",
    "\n",
    "model.add(Conv2D(64, (2, 2)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), data_format=\"channels_first\"))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(3))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=lr),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "56/56 [==============================] - 31s 562ms/step - loss: 1.1767 - acc: 0.6317 - val_loss: 1.0794 - val_acc: 0.7589\n",
      "Epoch 2/50\n",
      "56/56 [==============================] - 28s 500ms/step - loss: 1.0873 - acc: 0.6272 - val_loss: 1.0635 - val_acc: 0.7589\n",
      "Epoch 3/50\n",
      "56/56 [==============================] - 27s 486ms/step - loss: 1.0658 - acc: 0.6445 - val_loss: 1.0474 - val_acc: 0.7589\n",
      "Epoch 4/50\n",
      "56/56 [==============================] - 28s 503ms/step - loss: 1.0565 - acc: 0.6217 - val_loss: 1.0326 - val_acc: 0.7589\n",
      "Epoch 5/50\n",
      "56/56 [==============================] - 28s 498ms/step - loss: 1.0438 - acc: 0.6475 - val_loss: 1.0176 - val_acc: 0.7589\n",
      "Epoch 6/50\n",
      "56/56 [==============================] - 29s 526ms/step - loss: 1.0280 - acc: 0.6669 - val_loss: 1.0025 - val_acc: 0.7589\n",
      "Epoch 7/50\n",
      "56/56 [==============================] - 27s 487ms/step - loss: 1.0186 - acc: 0.6579 - val_loss: 0.9875 - val_acc: 0.7589\n",
      "Epoch 8/50\n",
      "56/56 [==============================] - 27s 482ms/step - loss: 1.0081 - acc: 0.6562 - val_loss: 0.9733 - val_acc: 0.7589\n",
      "Epoch 9/50\n",
      "56/56 [==============================] - 32s 575ms/step - loss: 0.9989 - acc: 0.6535 - val_loss: 0.9593 - val_acc: 0.7589\n",
      "Epoch 10/50\n",
      "56/56 [==============================] - 29s 517ms/step - loss: 0.9911 - acc: 0.6468 - val_loss: 0.9464 - val_acc: 0.7589\n",
      "Epoch 11/50\n",
      "56/56 [==============================] - 23s 417ms/step - loss: 0.9766 - acc: 0.6624 - val_loss: 0.9332 - val_acc: 0.7589\n",
      "Epoch 12/50\n",
      "56/56 [==============================] - 25s 440ms/step - loss: 0.9733 - acc: 0.6468 - val_loss: 0.9210 - val_acc: 0.7589\n",
      "Epoch 13/50\n",
      "56/56 [==============================] - 24s 421ms/step - loss: 0.9582 - acc: 0.6602 - val_loss: 0.9089 - val_acc: 0.7589\n",
      "Epoch 14/50\n",
      "56/56 [==============================] - 23s 407ms/step - loss: 0.9540 - acc: 0.6490 - val_loss: 0.8981 - val_acc: 0.7589\n",
      "Epoch 15/50\n",
      "56/56 [==============================] - 22s 400ms/step - loss: 0.9444 - acc: 0.6518 - val_loss: 0.8872 - val_acc: 0.7589\n",
      "Epoch 16/50\n",
      "56/56 [==============================] - 23s 403ms/step - loss: 0.9439 - acc: 0.6406 - val_loss: 0.8772 - val_acc: 0.7589\n",
      "Epoch 17/50\n",
      "56/56 [==============================] - 22s 400ms/step - loss: 0.9376 - acc: 0.6423 - val_loss: 0.8671 - val_acc: 0.7589\n",
      "Epoch 18/50\n",
      "56/56 [==============================] - 24s 430ms/step - loss: 0.9315 - acc: 0.6372 - val_loss: 0.8574 - val_acc: 0.7589\n",
      "Epoch 19/50\n",
      "56/56 [==============================] - 26s 456ms/step - loss: 0.9274 - acc: 0.6401 - val_loss: 0.8485 - val_acc: 0.7589\n",
      "Epoch 20/50\n",
      "56/56 [==============================] - 24s 424ms/step - loss: 0.9145 - acc: 0.6462 - val_loss: 0.8395 - val_acc: 0.7589\n",
      "Epoch 21/50\n",
      "56/56 [==============================] - 25s 451ms/step - loss: 0.8988 - acc: 0.6618 - val_loss: 0.8306 - val_acc: 0.7589\n",
      "Epoch 22/50\n",
      "56/56 [==============================] - 26s 459ms/step - loss: 0.9233 - acc: 0.6177 - val_loss: 0.8234 - val_acc: 0.7589\n",
      "Epoch 23/50\n",
      "56/56 [==============================] - 24s 421ms/step - loss: 0.8996 - acc: 0.6479 - val_loss: 0.8150 - val_acc: 0.7589\n",
      "Epoch 24/50\n",
      "56/56 [==============================] - 25s 438ms/step - loss: 0.8961 - acc: 0.6456 - val_loss: 0.8074 - val_acc: 0.7589\n",
      "Epoch 25/50\n",
      "56/56 [==============================] - 24s 426ms/step - loss: 0.8668 - acc: 0.6779 - val_loss: 0.7994 - val_acc: 0.7589\n",
      "Epoch 26/50\n",
      "56/56 [==============================] - 25s 449ms/step - loss: 0.8885 - acc: 0.6412 - val_loss: 0.7930 - val_acc: 0.7589\n",
      "Epoch 27/50\n",
      "56/56 [==============================] - 25s 449ms/step - loss: 0.8826 - acc: 0.6406 - val_loss: 0.7870 - val_acc: 0.7589\n",
      "Epoch 28/50\n",
      "56/56 [==============================] - 23s 404ms/step - loss: 0.8752 - acc: 0.6484 - val_loss: 0.7811 - val_acc: 0.7589\n",
      "Epoch 29/50\n",
      "56/56 [==============================] - 24s 434ms/step - loss: 0.8702 - acc: 0.6496 - val_loss: 0.7749 - val_acc: 0.7589\n",
      "Epoch 30/50\n",
      "56/56 [==============================] - 27s 487ms/step - loss: 0.8749 - acc: 0.6412 - val_loss: 0.7696 - val_acc: 0.7589\n",
      "Epoch 31/50\n",
      "56/56 [==============================] - 23s 410ms/step - loss: 0.8668 - acc: 0.6440 - val_loss: 0.7647 - val_acc: 0.7589\n",
      "Epoch 32/50\n",
      "56/56 [==============================] - 22s 402ms/step - loss: 0.8687 - acc: 0.6403 - val_loss: 0.7601 - val_acc: 0.7589\n",
      "Epoch 33/50\n",
      "56/56 [==============================] - 24s 425ms/step - loss: 0.8607 - acc: 0.6434 - val_loss: 0.7556 - val_acc: 0.7589\n",
      "Epoch 34/50\n",
      "56/56 [==============================] - 25s 445ms/step - loss: 0.8652 - acc: 0.6473 - val_loss: 0.7513 - val_acc: 0.7589\n",
      "Epoch 35/50\n",
      "56/56 [==============================] - 22s 401ms/step - loss: 0.8441 - acc: 0.6585 - val_loss: 0.7469 - val_acc: 0.7589\n",
      "Epoch 36/50\n",
      "56/56 [==============================] - 23s 406ms/step - loss: 0.8557 - acc: 0.6412 - val_loss: 0.7435 - val_acc: 0.7589\n",
      "Epoch 37/50\n",
      "56/56 [==============================] - 23s 402ms/step - loss: 0.8693 - acc: 0.6311 - val_loss: 0.7406 - val_acc: 0.7589\n",
      "Epoch 38/50\n",
      "56/56 [==============================] - 23s 411ms/step - loss: 0.8346 - acc: 0.6669 - val_loss: 0.7363 - val_acc: 0.7589\n",
      "Epoch 39/50\n",
      "56/56 [==============================] - 25s 443ms/step - loss: 0.8422 - acc: 0.6579 - val_loss: 0.7327 - val_acc: 0.7589\n",
      "Epoch 40/50\n",
      "56/56 [==============================] - 24s 424ms/step - loss: 0.8541 - acc: 0.6367 - val_loss: 0.7304 - val_acc: 0.7589\n",
      "Epoch 41/50\n",
      "56/56 [==============================] - 23s 403ms/step - loss: 0.8405 - acc: 0.6496 - val_loss: 0.7276 - val_acc: 0.7589\n",
      "Epoch 42/50\n",
      "56/56 [==============================] - 23s 405ms/step - loss: 0.8546 - acc: 0.6378 - val_loss: 0.7258 - val_acc: 0.7589\n",
      "Epoch 43/50\n",
      "56/56 [==============================] - 23s 412ms/step - loss: 0.8407 - acc: 0.6445 - val_loss: 0.7234 - val_acc: 0.7589\n",
      "Epoch 44/50\n",
      "56/56 [==============================] - 24s 420ms/step - loss: 0.8245 - acc: 0.6602 - val_loss: 0.7205 - val_acc: 0.7589\n",
      "Epoch 45/50\n",
      "56/56 [==============================] - 23s 411ms/step - loss: 0.8416 - acc: 0.6484 - val_loss: 0.7185 - val_acc: 0.7589\n",
      "Epoch 46/50\n",
      "56/56 [==============================] - 24s 436ms/step - loss: 0.8337 - acc: 0.6595 - val_loss: 0.7165 - val_acc: 0.7589\n",
      "Epoch 47/50\n",
      "56/56 [==============================] - 24s 424ms/step - loss: 0.8269 - acc: 0.6696 - val_loss: 0.7140 - val_acc: 0.7589\n",
      "Epoch 48/50\n",
      "56/56 [==============================] - 23s 408ms/step - loss: 0.8458 - acc: 0.6345 - val_loss: 0.7131 - val_acc: 0.7589\n",
      "Epoch 49/50\n",
      "56/56 [==============================] - 23s 405ms/step - loss: 0.8444 - acc: 0.6384 - val_loss: 0.7121 - val_acc: 0.7589\n",
      "Epoch 50/50\n",
      "56/56 [==============================] - 23s 408ms/step - loss: 0.8574 - acc: 0.6306 - val_loss: 0.7114 - val_acc: 0.7589\n"
     ]
    }
   ],
   "source": [
    "# Fit the model \n",
    "model.fit_generator(\n",
    "        train_gen,\n",
    "        steps_per_epoch = 1800 // batch_size,\n",
    "        epochs=50,\n",
    "        validation_data = val_gen,\n",
    "        validation_steps = 250 // batch_size)\n",
    "\n",
    "\n",
    "model.save('models/model.h5')\n",
    "model.save_weights('models/weights.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Erstelle eine Confusion matrix basierend auf den Ausgaben des Netzes für die Validierungsdaten und berechne den ROC AUC für die Klasse cheetah. Du kannst hierfür optional die scikit-learn Bibliothek verwenden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretrained network\n",
    "\n",
    "Lade nun ein auf Imagenet vortrainiertes Netzwerk und klassifiziere damit die Validierungsdaten. Eine Anleitung für keras findest du hier: https://keras.io/applications\n",
    "\n",
    "Du kannst selber entscheiden, welche Netzwerkarchitektur du verwendest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Da der ImageNet-Datensatz auch die Klassen cheetah und leopard enthält, können wir sogar ohne transfer learning das vortrainierte Netzwerk evaluieren. Interpretiere alle Klassen außer cheetah und leopard als unknown und berechne wie im vorherigen Schritt die Confusion matrix und den ROC AUC score für die Klasse cheetah."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer learning\n",
    "\n",
    "Das vortrainierte Netzwerk kann nun mit unseren Daten weitertrainiert werden. Ersetze dafür das letzte Layer in dem Netzwerk mit einem Dense Layer mit 3 Ausgaben für unsere Klassen cheetah, leopard und unknown. Du kannst selbst entscheiden, ob du nun das komplette Netzwerk mit trainierst oder nur das neu eingefügte, letzte Layer.\n",
    "\n",
    "Auch hierfür kannst du dich wieder an der keras Anleitung orientieren: https://keras.io/applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluiere das so trainierte Netzwerk wie in den letzten beiden Aufgaben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auswertung\n",
    "\n",
    "Beschreibe kurz qualitativ die Resultate. Wie unterscheiden sich die trainierten Netzwerke, zum Beispiel im Bezug auf die Genauigkeit oder die Laufzeit? Welche Entscheidungen musstest du bei der Erfüllung der Aufgaben treffen und warum hast du dich für den von dir gewählten Weg entschieden?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
